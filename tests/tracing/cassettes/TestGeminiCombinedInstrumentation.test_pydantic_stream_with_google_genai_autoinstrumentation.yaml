interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "Say hello."}], "role": "user"}], "generationConfig":
      {"responseModalities": ["TEXT"]}}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, zstd
      Connection:
      - keep-alive
      Content-Length:
      - '121'
      Content-Type:
      - application/json
      Host:
      - generativelanguage.googleapis.com
      User-Agent:
      - google-genai-sdk/1.62.0 gl-python/3.13.12
      X-Server-Timeout:
      - '600'
      x-goog-api-client:
      - google-genai-sdk/1.62.0 gl-python/3.13.12
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse
  response:
    body:
      string: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"Hello!\"}],\"role\":
        \"model\"},\"finishReason\": \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\":
        4,\"candidatesTokenCount\": 2,\"totalTokenCount\": 25,\"promptTokensDetails\":
        [{\"modality\": \"TEXT\",\"tokenCount\": 4}],\"thoughtsTokenCount\": 19},\"modelVersion\":
        \"gemini-2.5-flash\",\"responseId\": \"hlOLaeXqJ42YkdUP34e0mAY\"}\r\n\r\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Disposition:
      - attachment
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 10 Feb 2026 15:49:26 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=577
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
version: 1
